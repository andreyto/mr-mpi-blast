An example of large-scale mr-mpi-blast experiments


Updated: 12/20/2011
By Seung-Jin Sul (ssul@jcvi.org)


This document introduces one of our large-scale BLAST experiments using 
mr-mpi-blast. We will discuss input/output files, parameter settings, and other 
considerations. 
    
    
(1) XSEDE TACC Ranger Cluster Architecture

    The Sun Constellation Linux Cluster, named Ranger, is one of the largest 
    computational resources in the world. Ranger was made possible by a 
    grant awarded by the National Science Foundation in September 2006 to 
    TACC and its partners including Sun Microsystems, Arizona State 
    University, and Cornell University. Ranger entered formal production on 
    February 4, 2008 and supports high-end computational science for NSF 
    XSEDE researchers throughout the United States, academic institutions 
    within Texas, and components of the University of Texas System. The 
    Ranger cluster which provides 3,936 16-way SMP compute nodes providing 
    15,744 AMD Opteron(TM) processors. Each node has 16 cores with 32GB 
    RAM. The memory subsystem has a 1.0 GHz HyperTransport system Bus, and 
    2 channels with 667 MHz DDR2 DIMMS. Ranger nodes are interconnected 
    using InfiniBand technology. Also it supports Lustre shared file system 
    hosted on 72 disk servers.
    

(2) Prepare Query Files

    The purpose of the mr-mpi-blast experiment is to analyze the similarity 
    space of query sequences generated from NCBI RefSeq microbial genome 
    sequences against NCBI RefSeq microbial databases. For constructing 
    queries, all NCBI RefSeq microbial sequences are downloaded in a FASTA 
    file and a set of queries is generated. The original sequences are 
    splitted by 1kbp length with 500bp overlap. We prepare total 245,00,447 
    queries (~ 70Gbp). 
            

(3) Prepare BLAST Databases

    The NCBI RefSeq microbial genome sequences are formatted by using the 
    "makeblastdb" NCBI utility. Total 329,924 sequences are formatted in 
    three 1GB database partitions. Those database names are listed in 
    "dblist.txt" file for running mr-mpi-blast.
    
    $ makeblastdb -in refseq_microbial.fasta -dbtype nucl -logfile blastdbmake.log
      
        329,924 sequences; 12494903041 total bases
        Database: ./refseq_microbial.fasta

           329,924 sequences; 12,494,903,041 total bases

        Date: May 23, 2011  6:49 PM     Longest sequence: 13,033,779 bases

        Volumes:
           .../refseq_microbial.00
           .../refseq_microbial.01
           .../refseq_microbial.02


(4) Running mr-mpi-blast

    In our experience on Ranger with 1,024~2,048 cores, the file system of 
    the underlying cluster system is definitely overloaded by the 
    out-of-core disk operation (Actually Ranger staffs monitored the system 
    load and found it degraded the file system performance). So we decided 
    not to allow the out-of-core and partition the input qeury file was 
    physically partitioned into 63 files and the size of file varies 1 ~ 
    1.5GB. This eliminates the possibility of page overflow in the 
    MapReduce-MPI because of the issue of out-of-core operation. To decide 
    the size of the query file partition, we ran tests with different 
    partition sizes, for example, 500MB, 750MB, 1GB, and so on with 
    disabling the out-of-core operation. We found 1 ~ 1.5GB query files are 
    safe for running mr-mpi-blast without allowing out-of-core operation 
    for the experiments. 
        
    The other parameter settings are followed:
    
        in "examples/refseq-all-vs-all/mrblast.ini":
    
            VERBOSITY   1
            TIMER       1
            MEMSIZE     128
            OUTOFCORE   -1
            MAPSTYLE    3        
            BLOCKSIZE   500000
            NUMITER     1
            ISPROTEIN   0
            ISQIDGI     0       
        
        
    The number of query block created by BLOCKSIZE=500000 is around 2,500. Thus 
    the total number of work items is around 7,500. We used 2,048 cores for 
    this run. We first request 2,048 cores from "normal" queue with 24 
    hours runtime. The partitioned query files are placed in different 
    subdirectories. The script "ranger-for-loop-run.sh" does a little 
    trick. Each subdirectory is visited one by one and mr-mpi-blast runs 
    with the data in the directory. When completed, "SUCCESS" file is created
    to represent BLAST search for this partition is done. If the runtime 
    request (24hours) is not ended, visit the next subdirectory and run 
    mr-mpi-blast. If the requested runtime is ended, the running mr-mpi-blast 
    process will be aborted but "SUCCESS" will not be recorded for the 
    subdirectory. Thus, the next allocation will start from the aborted 
    subdirectory. The SGE job script and program looping script are following.
    
       
        in "examples/refseq-all-vs-all/sge_job_script.job":
        
            #$ -N r2048
            #$ -cwd
            #$ -o $JOB_NAME.o$JOB_ID
            #$ -j n
            #$ -A SGE_ACCOUNT 
            #$ -q normal
            #$ -pe 16way 2048
            #$ -V
            #$ -l h_rt=24:00:00
            sh ranger-for-loop-run.sh



        in "examples/refseq-all-vs-all/ranger-for-loop-run.sh":
        
            #!/bin/sh
            Directory="./"
            for direc in $Directory* ; do
                bDone=0
                if [[ -d $direc ]]; then
                    echo $direc
                    FileList=$(find $direc -type f)
                    for file2 in $FileList ; do
                        if [[ $file2 == *SUCCESS ]] ; then
                            echo "already done in $direc"
                            bDone=1
                            break
                        fi
                    done
                    
                    if [[ bDone -eq 0 ]]; then
                        topdir=$(pwd)
                        cd $direc            
                        rm -rf output-*
                        echo "run job in $direc"
                        ibrun mrblast -evalue 1e-4 -num_threads 1 -window_size 0 -word_size 11 -searchsp 0 -num_descriptions 500 -num_alignments 10000 -penalty -5 -reward 4  -lcase_masking -dust yes -soft_masking true -max_target_seqs 2147483647
            
            echo "job done in $direc"
                        cp ../*.o* .
                        cp ../*.e* .
                        touch SUCCESS
                        cd $topdir
                    fi
                fi
            done
   
    
(5) Converting the Result File
 
    After completion, each subdirectory has a set of resulting hit files in 
    binary format. Finally, those files (~74GB in total) are collected in HD5 
    database (~67GB).
    
    
    
    
    
