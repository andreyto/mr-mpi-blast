An example of large-scale mr-mpi-blast experiment


Updated: 12/27/2011
By Seung-Jin Sul (ssul@jcvi.org)


This document introduces one of our large-scale BLAST experiments using 
mr-mpi-blast. We will discuss input/output files, parameter settings, and other 
considerations. 
    
    
(1) XSEDE TACC Ranger cluster architecture

    The Sun Constellation Linux Cluster, named Ranger, is one of the largest 
    computational resources in the world. Ranger was made possible by a 
    grant awarded by the National Science Foundation in September 2006 to 
    TACC and its partners including Sun Microsystems, Arizona State 
    University, and Cornell University. Ranger entered formal production on 
    February 4, 2008 and supports high-end computational science for NSF 
    XSEDE researchers throughout the United States, academic institutions 
    within Texas, and components of the University of Texas System. The 
    Ranger cluster which provides 3,936 16-way SMP compute nodes providing 
    15,744 AMD Opteron(TM) processors. Each node has 16 cores with 32GB 
    RAM. The memory subsystem has a 1.0 GHz HyperTransport system Bus, and 
    2 channels with 667 MHz DDR2 DIMMS. Ranger nodes are interconnected 
    using InfiniBand technology. Also it supports Lustre shared file system 
    hosted on 72 disk servers.
    

(2) Prepare query file

    The purpose of the mr-mpi-blast experiment is to analyze the similarity 
    space by searching a set of query sequences simulated from NCBI RefSeq 
    microbial genome sequences against NCBI RefSeq microbial database 
    itself. For constructing queries, all NCBI RefSeq microbial sequences 
    are downloaded in a FASTA file and the sequences are splitted by 1kbp 
    length with 500bp overlap. We prepare total 245,00,447 queries (~ 70Gbp). 
            

(3) Prepare BLAST databases

    The NCBI RefSeq microbial genome sequences are formatted by using the 
    "makeblastdb" NCBI utility. Total 329,924 sequences are formatted in 
    three 1GB database partitions. Those database partition names are 
    listed in "dblist.txt" file for running mr-mpi-blast. 
    
    $ makeblastdb -in refseq_microbial.fasta -dbtype nucl -logfile blastdbmake.log
      
        329,924 sequences; 12494903041 total bases
        Database: ./refseq_microbial.fasta

           329,924 sequences; 12,494,903,041 total bases

        Date: May 23, 2011  6:49 PM     Longest sequence: 13,033,779 bases

        Volumes:
           .../refseq_microbial.00
           .../refseq_microbial.01
           .../refseq_microbial.02


(4) Running mr-mpi-blast

    For the initial parameter values, we used 128MB page size, 1GB size of 
    database partition, and 1Mbp block size. In our experience on Ranger 
    with 1,024~2,048 cores, the file system of the cluster system was 
    definitely overloaded by the out-of-core disk operation (Actually 
    Ranger staffs monitored the system load and found the file system 
    performance was affected by the excessive disk I/O). So we decided not 
    to allow the out-of-core and to partition the input query file into 
    smaller files to eliminate the possibility of the MapReduce page 
    overflow. To decide the size of the query file partition, we ran tests 
    with different query partition file sizes, for example, 500MB, 750MB, 
    1GB, and so on with disabling the out-of-core operation. We found 1 ~ 
    1.5GB query file partitions were safe for running mr-mpi-blast which 
    results in having 63 query files. Because the query file size is 
    decreased by partitioning, we set the block size as 500Kbp so as to 
    prepare enough number of work items.
                
    The other parameter settings are followed:
    
        In file, "examples/refseq-all-vs-all/mrblast.ini":
    
            VERBOSITY   1
            TIMER       1
            MEMSIZE     128
            OUTOFCORE   -1
            MAPSTYLE    3        
            BLOCKSIZE   500000
            NUMITER     1
            ISPROTEIN   0
            ISQIDGI     0       

    * NOTE
      The "ISQIDGI" parameter is now obsolete. The current version uses generated
      serial number as unique query ID. 
    
    The number of query blocks created by the block size of 500Kbp is around 
    2,500. Thus the total number of work items is around 7,500. We 
    requested 2,048 cores from "normal" queue with 24 hours runtime. The 63 
    partitioned query files are placed in different subdirectories. The 
    script "ranger-for-loop-run.sh" does a little trick. Each subdirectory 
    is visited one by one and mr-mpi-blast runs with the data in the 
    directory. When completed, "SUCCESS" file is created to represent BLAST 
    search for this partition is done. If the runtime request (24hours) is 
    not ended, visit the next subdirectory and run mr-mpi-blast. If the 
    requested runtime is ended, the running mr-mpi-blast process will be 
    aborted but "SUCCESS" will not be recorded for the subdirectory. Thus, 
    when the next allocation is started. the mr-mpi-blast can run from the 
    previously aborted subdirectory. The SGE job script and program looping 
    script are following.
    
        In file, "examples/refseq-all-vs-all/sge_job_script.job":
        
            #$ -N r2048
            #$ -cwd
            #$ -o $JOB_NAME.o$JOB_ID
            #$ -j n
            #$ -A SGE_ACCOUNT 
            #$ -q normal
            #$ -pe 16way 2048
            #$ -V
            #$ -l h_rt=24:00:00
            sh ranger-for-loop-run.sh



        In file, "examples/refseq-all-vs-all/ranger-for-loop-run.sh":
        
            #!/bin/sh
            Directory="./"
            for direc in $Directory* ; do
                bDone=0
                if [[ -d $direc ]]; then
                    echo $direc
                    FileList=$(find $direc -type f)
                    for file2 in $FileList ; do
                        if [[ $file2 == *SUCCESS ]] ; then
                            echo "already done in $direc"
                            bDone=1
                            break
                        fi
                    done
                    
                    if [[ bDone -eq 0 ]]; then
                        topdir=$(pwd)
                        cd $direc            
                        rm -rf output-*
                        echo "run job in $direc"
                        ibrun mrblast -evalue 1e-4 -num_threads 1 -window_size 0 -word_size 11 -searchsp 0 -num_descriptions 500 -num_alignments 10000 -penalty -5 -reward 4  -lcase_masking -dust yes -soft_masking true -max_target_seqs 2147483647
            
            echo "job done in $direc"
                        cp ../*.o* .
                        cp ../*.e* .
                        touch SUCCESS
                        cd $topdir
                    fi
                fi
            done
   
    
(5) Converting the result file
 
    After completion, each subdirectory has a set of resulting hit files in 
    binary format. Those files (~74GB in total) are collected in HDF5 
    database (~67GB).
    
    
    
    
    
